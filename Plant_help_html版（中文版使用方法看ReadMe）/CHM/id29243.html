<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">

<!--
This software and related documentation are proprietary to Siemens Product Lifecycle Management Software Inc.

(c) 2013 Siemens Product Lifecycle Management Software Inc. All Rights Reserved. 

All trademarks belong to their respective holders.
-->
<html>
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
      <title>Configuring the Neural Network</title>
      
      <meta name="MS-HKWD" content="Configuring the Neural Network">
      
      <link type="text/css" href="css/base.css" rel="stylesheet">
   </head>
   <body class="bodydocs" bgcolor="#FFFFFF">
      <div class="title_topic4" id="xps10_pagetitle">Configuring the Neural Network</div>
      <hr noshade="true">
      <div class="insideNavLinks"><span><a class="link" href="id54338.html"><img border="0" src="../../../../../../icons/previous.gif" title="Previous Page:Forecasting"></a><a class="link" href="id96176.html"><img border="0" src="../../../../../../icons/next.gif" title="Next Page:Calculating the Output Values"></a></span></div>
      <table align="center" class="simpleHTMLminitoc" width="95%">
         <tr>
            <td class="simpleHTMLminitoc"><span class="simpleHTMLminitoc"><a href="id13813.html">2D Reference Help</a></span> &gt; <span class="simpleHTMLminitoc"><a href="id54344.html">Tools</a></span> &gt; <span class="simpleHTMLminitoc"><a href="id50388.html">Artificial Neural Network</a></span> &gt; <span class="simpleHTMLminitoc">Configuring the Neural Network</span></td>
         </tr>
      </table>
      <div class="contentType_"><span id="ndxgenid_PlantSimulationENU_12760"></span><p class="para_topic"> To configure the neural network, select the command  Extended Settings in the dialog of the neural network.</p>
         <p class="para_topic"> The training algorithm is the back-propagation-method, which is a gradient descent method. This algorithm minimizes the error between the outputs of the neural network and the given training data. The default parameters of the algorithm are suited for the most frequently used applications. If the <em>NeuralNet</em> contains a trained neural network, the dialog items, which control the structure of the neural network and the results of the training are deactivated. When you reset the artificial neural network, the dialog items, which control the output of the results of the training are deactivated. This applies to the dialog items of the dialogs of the neural network proper and to the configuration dialog.
         </p>
         <p class="para_topic"> You can define settings for the structure of the neural network on the tab <b class="uiTerm">Network Design</b>.
         </p>
         <table bgcolor="#FFFFFF" cellpadding="2" cellspacing="1" align="center">
            
            <colgroup span="1">
               
               <col span="1" width="50%">
               
               <col span="1" width="50%">
               
            </colgroup>
            
            <tbody>
               
               <tr>
                  
                  <td colspan="1" rowspan="1">
                     
                     <p class="para_td_last"><img align="bottom" src="../graphics/graphicLibrary/ReferenceHelp/Tools/NN51.gif" border="0"></p>
                     
                  </td>
                  
                  <td colspan="1" rowspan="1">
                     
                     <p class="para_td_last"><img align="bottom" src="../graphics/graphicLibrary/ReferenceHelp/Tools/NN5.gif" border="0"></p>
                     
                  </td>
                  
               </tr>
               
            </tbody>
            
         </table>
         <p class="para_topic" align="center"> Configuring the neural network</p>
         <p class="para_topic"> Under the group  Number of layers you can select to use a tri-layered or a four-layered neural network. One hidden layer, i.e., a tri-layered neural network, will suffice for most applications. </p>
         <p class="para_topic"> Under the group Weighting between the layers you can view tables, which contain a weighting of the strength of the connections between the nodes of the layers.  These weights are the results of the training and represent the actual knowledge about the relations between the input and the output values. An interpretation of the contents of the individual weights is only possible for simple small networks.</p>
         <p class="para_topic"> On the tab  Training you can change the parameters of the training algorithm. </p>
         <p align="center"><img align="bottom" src="../graphics/graphicLibrary/ReferenceHelp/Tools/NN6.gif"></p>
         <p class="para_topic"> You will set User-defined parameters of the neural network depending on the problem you want to solve. Here you either have to fall back on experience values or find suitable values through trials. To use predefined Calculated parameters, select the check boxes to their left. </p>
         <p class="para_topic"> The <b class="uiTerm">Activation</b> function, which you can select under User-defined parameters, is applied to the cumulated influence of all nodes of a layer onto the next layer. You can also enter the Magnitude of activation of the cumulated influence. 
         </p>
         <p class="para_topic"> The given data are classified as training data and validation data, which is only used for calculating the error of the neural network. You can enter the Percentage of the training data.</p>
         <p class="para_topic"> If the weights from one training step to the next do not change much during the algorithm, continuing the training algorithm is not effective. The <em> NeuralNet</em> checks after each twenty training steps if the relative changes of the weights are below the percentage, which you enter into the text box Re-initialization . When the training algorithm arrived at a local minimum, the <em> NeuralNet</em> will be re-initialized. This way a better local minimum might be found. During a re-initialization the weights are chosen randomly. You can enter the Magnitude of weights. The <em> NeuralNet</em> suggests a value depending on the value of the Activation function .
         </p>
         <p class="para_topic"> The gradient descent method is executed for each individual weight with an individual adjustment of the step size of the weight change. The training factor <em> Eta</em> controls the step size. <em> Eta</em> is dynamically adjusted between a minimum and a maximum value during the training algorithm. You can set the minimum and the maximum value of the training factor on the tab Training . Initially the training algorithm selects the mean value of the minimum and the maximum training factor. We recommend to set the Eta increase factor and the Eta decrease factor depending on the minimum and the maximum value of the training factor. The <em> NeuralNet</em> suggests an Eta increase factor, which after a tenfold multiplication of the Eta increase factor , transfers the initial value of <em> Eta</em> into the maximum value. 
         </p>
         <p class="para_topic"> In addition to adjusting the training/learning rate, the training algorithm can be accelerated by adding a momentum coefficient. For this a certain portion  Alpha of the weight adjustment from the previous training step is added to the current training step. You can enter a value for the parameter <em> Alpha</em> , i.e., the  Momentum coefficient on the tab  Training . 
         </p>
         <p class="para_topic"> To prevent that the training algorithm changes the weights too much while searching for the minimum error, the weights are not corrected after each error computation, but only after the number of data sets, which you enter into the text box Error batch size. When correcting the weights, the <em> NeuralNet</em> uses the mean value of the errors of these data sets. The value, which the <em> NeuralNet</em> suggests, results from the number of data sets for the training.
         </p>
         <p class="para_topic"> Under  Noise on the tab  Settings you can select if the noise is to be taken into consideration for error correction. Noise can be incorporated through the variance of the output values or through a percentage, which you enter. If the deviations are located within a tolerance interval, which results from the variance or the percentage, the error will be set to 0.</p>
         <p align="center"><img align="bottom" src="../graphics/graphicLibrary/ReferenceHelp/Tools/NN7.gif"></p>
         <p class="para_topic"> Under  Settings &gt; Forecast you can set the parameters for the optimization algorithm for the forecast. The increments of the input values determines the accuracy with which the input values are calculated. The optimization algorithm is a variant of Simulated Annealing, which executes the  Number of iteration steps at the most. As this procedure is controlled by chance, it is advisable to start the optimization several times and then compare the results.</p>
         <p class="para_topic"> The forecast searches for the most cost-efficient solution for a set of input values. For a proportional cost calculation, you will enter the cost factors for each input value. You can also run more complex cost calculations with a <em> Method</em>, whose parameters are provided by a table with the input values. The output value of this <em>Method</em> (of data type <em>real</em>) are the resulting costs.
         </p>
      </div>
      <div class="insideNavLinks"><span><a class="link" href="id54338.html"><img border="0" src="../../../../../../icons/previous.gif" title="Previous Page:Forecasting"></a><a class="link" href="id96176.html"><img border="0" src="../../../../../../icons/next.gif" title="Next Page:Calculating the Output Values"></a></span></div>
   </body>
</html>